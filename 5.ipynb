{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4-aQ4eTeAZD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pylab as pylab\n",
        "import numpy as np\n",
        "import re\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gd8vbXRAeAZG"
      },
      "outputs": [],
      "source": [
        "sentences = \"\"\"Sample text paragraph\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSSWBE0AeAZH"
      },
      "outputs": [],
      "source": [
        "sentences = re.sub('[^A-Za-z0-9]+', ' ', sentences)\n",
        "sentences = re.sub(r'(?:^| )\\w(?:$| )', ' ', sentences).strip()\n",
        "sentences = sentences.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ2vk9cdeAZI"
      },
      "outputs": [],
      "source": [
        "words = sentences.split()\n",
        "vocab = set(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzRZphwSeAZI"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vocab)\n",
        "embed_dim = 10\n",
        "context_size = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKJSPgGieAZJ"
      },
      "outputs": [],
      "source": [
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "ix_to_word = {i: word for i, word in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdLHuTVTeAZK"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "for i in range(2, len(words) - 2):\n",
        "    context = [words[i - 2], words[i - 1], words[i + 1], words[i + 2]]\n",
        "    target = words[i]\n",
        "    data.append((context, target))\n",
        "print(data[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-CL15cKeAZK"
      },
      "outputs": [],
      "source": [
        "embeddings =  np.random.random_sample((vocab_size, embed_dim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOpgsjQpeAZL"
      },
      "outputs": [],
      "source": [
        "def linear(m, theta):\n",
        "    w = theta\n",
        "    return m.dot(w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "606wDT_KeAZL"
      },
      "outputs": [],
      "source": [
        "def log_softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return np.log(e_x / e_x.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tua8jt6ueAZM"
      },
      "outputs": [],
      "source": [
        "def NLLLoss(logs, targets):\n",
        "    out = logs[range(len(targets)), targets]\n",
        "    return -out.sum()/len(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEE5e32QeAZM"
      },
      "outputs": [],
      "source": [
        "def log_softmax_crossentropy_with_logits(logits,target):\n",
        "\n",
        "    out = np.zeros_like(logits)\n",
        "    out[np.arange(len(logits)),target] = 1\n",
        "    \n",
        "    softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n",
        "    \n",
        "    return (- out + softmax) / logits.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rGVGjz-eAZM"
      },
      "outputs": [],
      "source": [
        "def forward(context_idxs, theta):\n",
        "    m = embeddings[context_idxs].reshape(1, -1)\n",
        "    n = linear(m, theta)\n",
        "    o = log_softmax(n)\n",
        "    \n",
        "    return m, n, o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvM-K_-UeAZN"
      },
      "outputs": [],
      "source": [
        "def backward(preds, theta, target_idxs):\n",
        "    m, n, o = preds\n",
        "    \n",
        "    dlog = log_softmax_crossentropy_with_logits(n, target_idxs)\n",
        "    dw = m.T.dot(dlog)\n",
        "    \n",
        "    return dw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jB424VSeAZN"
      },
      "outputs": [],
      "source": [
        "def optimize(theta, grad, lr=0.03):\n",
        "    theta -= grad * lr\n",
        "    return theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnUOU46ueAZN"
      },
      "outputs": [],
      "source": [
        "theta = np.random.uniform(-1, 1, (2 * context_size * embed_dim, vocab_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0PKjqsheAZO"
      },
      "outputs": [],
      "source": [
        "epoch_losses = {}\n",
        "\n",
        "for epoch in range(80):\n",
        "\n",
        "    losses =  []\n",
        "\n",
        "    for context, target in data:\n",
        "        context_idxs = np.array([word_to_ix[w] for w in context])\n",
        "        preds = forward(context_idxs, theta)\n",
        "\n",
        "        target_idxs = np.array([word_to_ix[target]])\n",
        "        loss = NLLLoss(preds[-1], target_idxs)\n",
        "\n",
        "        losses.append(loss)\n",
        "\n",
        "        grad = backward(preds, theta, target_idxs)\n",
        "        theta = optimize(theta, grad, lr=0.03)\n",
        "        \n",
        "     \n",
        "    epoch_losses[epoch] = losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AftYSJHveAZO"
      },
      "outputs": [],
      "source": [
        "ix = np.arange(0,80)\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Epoch/Losses', fontsize=20)\n",
        "plt.plot(ix,[epoch_losses[i][0] for i in ix])\n",
        "plt.xlabel('Epochs', fontsize=12)\n",
        "plt.ylabel('Losses', fontsize=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeHSy-UbeAZP"
      },
      "outputs": [],
      "source": [
        "def predict(words):\n",
        "    context_idxs = np.array([word_to_ix[w] for w in words])\n",
        "    preds = forward(context_idxs, theta)\n",
        "    word = ix_to_word[np.argmax(preds[-1])]\n",
        "    \n",
        "    return word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WO4OoOV9eAZP"
      },
      "outputs": [],
      "source": [
        "predict(['we', 'are', 'to', 'study'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ6WkC0leAZP"
      },
      "outputs": [],
      "source": [
        "def accuracy():\n",
        "    wrong = 0\n",
        "\n",
        "    for context, target in data:\n",
        "        if(predict(context) != target):\n",
        "            wrong += 1\n",
        "            \n",
        "    return (1 - (wrong / len(data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvZZ5MCZeAZP"
      },
      "outputs": [],
      "source": [
        "accuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnukYQnMeAZQ"
      },
      "outputs": [],
      "source": [
        "predict(['processes', 'manipulate', 'things', 'study'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}